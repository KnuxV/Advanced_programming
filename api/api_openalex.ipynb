{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2feab3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import re\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e41fab7",
   "metadata": {},
   "source": [
    "# Collect focal papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4e2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstract(words):\n",
    "    n = max({idx  for name in words for idx in words[name]})+1\n",
    "    temp_list = [' ']*n\n",
    "    for word in words:\n",
    "        idxs = words[word]\n",
    "        for idx in idxs:\n",
    "            temp_list[idx] = word\n",
    "    abstract = ' '.join(temp_list)\n",
    "    return abstract\n",
    "\n",
    "def get_basic_infos(doc):\n",
    "    list_concepts = [concept['id'] for concept in doc['concepts']]\n",
    "    Source = None\n",
    "    if doc['primary_location']:\n",
    "        if 'source' in doc['primary_location']:\n",
    "            if doc['primary_location']['source']:\n",
    "                if 'id' in doc['primary_location']['source']:\n",
    "                    Source = int(re.sub(\"https://openalex.org/S\",\"\",doc['primary_location']['source']['id']))\n",
    "    infos = {'id':re.sub(\"https://openalex.org/\",\"\",doc['id']),\n",
    "    'doi':doc['doi'],\n",
    "    'year':doc['publication_year'],\n",
    "    'language':doc['language'],\n",
    "    'type':doc['type'],\n",
    "    'source':Source,\n",
    "    'nb_auth':len(doc['authorships']),\n",
    "    'auth_ids':'; '.join([re.sub(\"https://openalex.org/A\",\"\",auth['author']['id']) for auth in doc['authorships'] if auth['author']['id']]),\n",
    "    'countries' : '; '.join([auth['countries'][0] for auth in doc['authorships'] if auth['countries']]),\n",
    "    'institutions' : '; '.join([auth['institutions'][0]['id'] for auth in doc['authorships'] if auth['institutions']]),\n",
    "    'nb_citations': doc['cited_by_count'],\n",
    "    'title': doc['title'],\n",
    "    'abstract': get_abstract(doc['abstract_inverted_index']) if doc['abstract_inverted_index'] else None,\n",
    "    'nb_ref':doc['referenced_works_count'] ,\n",
    "    'concepts': '; '.join(list_concepts),\n",
    "    'references': '; '.join(doc['referenced_works'])}\n",
    "    \n",
    "    return infos\n",
    "\n",
    "def get_nb_pages(url, limit=50):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        count = data['meta']['count']\n",
    "        nb_pages = math.ceil(count/limit)\n",
    "        print(f\"Number of articles matched: {count}\")\n",
    "        print(f\"Number of pages: {nb_pages}\")\n",
    "    return nb_pages\n",
    "\n",
    "def get_articles(url,cursor = False,limit = 100):\n",
    "    if cursor:\n",
    "        url += f\"&cursor={cursor}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()    \n",
    "        articles = data['results']\n",
    "        if cursor:\n",
    "            next_cursor = data['meta']['next_cursor']\n",
    "            return articles, next_cursor\n",
    "        else:\n",
    "            return articles\n",
    "    else:\n",
    "        print(\"Failed to retrieve data:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_url(search, time_windows, concept_id, limit=100):\n",
    "    url = \"https://api.openalex.org/works?\"\n",
    "    if search:\n",
    "        search = search.replace(' ', '+')\n",
    "        title_search = f\"search={search}\"\n",
    "        url += title_search\n",
    "   \n",
    "    if time_windows or concept_id:\n",
    "        if search:\n",
    "            filter_ = '&filter='\n",
    "        else:\n",
    "            filter_ = 'filter='\n",
    "        url += filter_\n",
    "        \n",
    "        if time_windows:\n",
    "            filter_year = f\"publication_year:{time_windows}\"\n",
    "            url += filter_year\n",
    "        if concept_id:\n",
    "            if time_windows:\n",
    "                url += ','\n",
    "            filter_concept = f\"concepts.id:{concept_id}\"\n",
    "            url += filter_concept\n",
    "    url += \"&mailto=s.bianchini@unistra.fr\"\n",
    "    url += f\"&per-page={limit}\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6784f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concepts with labour+economics in display_name: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>display_name</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>level</th>\n",
       "      <th>description</th>\n",
       "      <th>works_count</th>\n",
       "      <th>cited_by_count</th>\n",
       "      <th>summary_stats</th>\n",
       "      <th>ids</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_thumbnail_url</th>\n",
       "      <th>international</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>related_concepts</th>\n",
       "      <th>counts_by_year</th>\n",
       "      <th>works_api_url</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/C145236788</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q28161</td>\n",
       "      <td>Labour economics</td>\n",
       "      <td>116484.914</td>\n",
       "      <td>1</td>\n",
       "      <td>functioning and dynamics of the markets for la...</td>\n",
       "      <td>569577</td>\n",
       "      <td>6498058</td>\n",
       "      <td>{'2yr_mean_citedness': 1.1874455353511881, 'h_...</td>\n",
       "      <td>{'openalex': 'https://openalex.org/C145236788'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'display_name': {'ar': 'اقتصاديات العمل', 'as...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C162324750', 'wi...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C162324750', 'wi...</td>\n",
       "      <td>[{'year': 2024, 'works_count': 8457, 'cited_by...</td>\n",
       "      <td>https://api.openalex.org/works?filter=concepts...</td>\n",
       "      <td>2024-09-01T12:17:38.151583</td>\n",
       "      <td>2016-06-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id                              wikidata  \\\n",
       "0  https://openalex.org/C145236788  https://www.wikidata.org/wiki/Q28161   \n",
       "\n",
       "       display_name  relevance_score  level  \\\n",
       "0  Labour economics       116484.914      1   \n",
       "\n",
       "                                         description  works_count  \\\n",
       "0  functioning and dynamics of the markets for la...       569577   \n",
       "\n",
       "   cited_by_count                                      summary_stats  \\\n",
       "0         6498058  {'2yr_mean_citedness': 1.1874455353511881, 'h_...   \n",
       "\n",
       "                                                 ids image_url  \\\n",
       "0  {'openalex': 'https://openalex.org/C145236788'...      None   \n",
       "\n",
       "  image_thumbnail_url                                      international  \\\n",
       "0                None  {'display_name': {'ar': 'اقتصاديات العمل', 'as...   \n",
       "\n",
       "                                           ancestors  \\\n",
       "0  [{'id': 'https://openalex.org/C162324750', 'wi...   \n",
       "\n",
       "                                    related_concepts  \\\n",
       "0  [{'id': 'https://openalex.org/C162324750', 'wi...   \n",
       "\n",
       "                                      counts_by_year  \\\n",
       "0  [{'year': 2024, 'works_count': 8457, 'cited_by...   \n",
       "\n",
       "                                       works_api_url  \\\n",
       "0  https://api.openalex.org/works?filter=concepts...   \n",
       "\n",
       "                 updated_date created_date  \n",
       "0  2024-09-01T12:17:38.151583   2016-06-24  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_concept_id(query):\n",
    "    query = query.replace(' ', '+')\n",
    "    url = f\"https://api.openalex.org/concepts?search={query}&per-page=200\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"Number of concepts with {query} in display_name: {data['meta']['count']}\")\n",
    "        concepts = data['results']\n",
    "        return concepts\n",
    "    else:\n",
    "        print(\"Failed to retrieve data:\", response.status_code)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "concepts = get_concept_id('labour economics')\n",
    "pd.DataFrame(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9de41-3240-43d2-a26f-f11487dcfb00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C185798385\n",
      "Number of articles matched: 232151\n",
      "Number of pages: 1161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 1160/1161 [1:00:27<00:03,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'countries'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1161/1161 [1:01:01<00:00,  3.15s/it]\n",
      " 49%|███████████████████████████████████▋                                     | 9285/19018 [7:40:54<7:34:09,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data: 503\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████▊                                     | 9315/19018 [7:59:02<7:24:30,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data: 503\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 19018/19018 [15:43:26<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2777526511\n",
      "Number of articles matched: 77774\n",
      "Number of pages: 389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 389/389 [18:14<00:00,  2.81s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8297/8297 [6:18:21<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C132010649\n",
      "Number of articles matched: 31017\n",
      "Number of pages: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [07:07<00:00,  2.74s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3602/3602 [2:37:54<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C18483071\n",
      "Number of articles matched: 11604\n",
      "Number of pages: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [02:41<00:00,  2.74s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1267/1267 [59:36<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C170477896\n",
      "Number of articles matched: 7732\n",
      "Number of pages: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [01:46<00:00,  2.74s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 897/897 [40:52<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C66283442\n",
      "Number of articles matched: 27545\n",
      "Number of pages: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 138/138 [06:29<00:00,  2.82s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2143/2143 [1:36:27<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C46362747\n",
      "Number of articles matched: 327068\n",
      "Number of pages: 1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1636/1636 [1:18:55<00:00,  2.89s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 11696/11696 [8:46:46<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2779679103\n",
      "Number of articles matched: 202844\n",
      "Number of pages: 1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1015/1015 [49:55<00:00,  2.95s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 17355/17355 [14:04:07<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C74172769\n",
      "Number of articles matched: 210215\n",
      "Number of pages: 1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1052/1052 [50:57<00:00,  2.91s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8143/8143 [6:08:53<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C94487597\n",
      "Number of articles matched: 118204\n",
      "Number of pages: 592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [30:20<00:00,  3.07s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12191/12191 [9:56:47<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2779356329\n",
      "Number of articles matched: 89043\n",
      "Number of pages: 446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 446/446 [22:38<00:00,  3.05s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10833/10833 [9:01:46<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2779918689\n",
      "Number of articles matched: 115982\n",
      "Number of pages: 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 580/580 [32:31<00:00,  3.36s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10677/10677 [8:32:57<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C51399673\n",
      "Number of articles matched: 73444\n",
      "Number of pages: 368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 368/368 [18:09<00:00,  2.96s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3531/3531 [2:46:34<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C87360688\n",
      "Number of articles matched: 76455\n",
      "Number of pages: 383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                            | 20/383 [01:05<19:27,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data: 500\n",
      "cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 383/383 [19:16<00:00,  3.02s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2833/2833 [2:09:35<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C138171918\n",
      "Number of articles matched: 112838\n",
      "Number of pages: 565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 565/565 [27:29<00:00,  2.92s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 5115/5115 [3:59:28<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C143916079\n",
      "Number of articles matched: 72141\n",
      "Number of pages: 361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 361/361 [17:54<00:00,  2.98s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4386/4386 [3:31:26<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C52121051\n",
      "Number of articles matched: 68007\n",
      "Number of pages: 341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 341/341 [15:56<00:00,  2.80s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2663/2663 [2:03:51<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2779134260\n",
      "Number of articles matched: 3583465\n",
      "Number of pages: 17918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████▍                    | 12744/17918 [11:35:28<3:51:20,  2.68s/it]"
     ]
    }
   ],
   "source": [
    "concepts = [#\"C140096630\",\n",
    "#\"C3020597237\",\n",
    "#\"C2780451532\",\n",
    "#\"C96250715\",\n",
    "#\"C15952604\",\n",
    "#\"C187691185\",\n",
    "\"C185798385\",\n",
    "\"C2777526511\",\n",
    "\"C132010649\",\n",
    "\"C18483071\",\n",
    "\"C170477896\",\n",
    "\"C66283442\",\n",
    "\"C46362747\",\n",
    "\"C2779679103\",\n",
    "\"C74172769\",\n",
    "\"C94487597\",\n",
    "\"C2779356329\",\n",
    "\"C2779918689\",\n",
    "\"C51399673\",\n",
    "\"C87360688\",\n",
    "\"C138171918\",\n",
    "\"C143916079\",\n",
    "\"C52121051\",\n",
    "\"C2779134260\",\n",
    "\"C121608353\",\n",
    "\"C104317684\",\n",
    "\"C204787440\",\n",
    "\"C116675565\",\n",
    "\"C118518473\",\n",
    "\"C2777267654\"\n",
    "]\n",
    "\n",
    "import os\n",
    "time_windows = '2000-2023'\n",
    "search = None\n",
    "limit = 200\n",
    "path_ = os.getcwd()\n",
    "    \n",
    "for concept_id in concepts:\n",
    "    print(concept_id)\n",
    "    os.chdir(path_)\n",
    "    if not os.path.exists(concept_id):\n",
    "        os.makedirs(concept_id)\n",
    "    os.chdir(concept_id)\n",
    "    url = get_url(search, time_windows, concept_id, limit)\n",
    "    nb_pages = get_nb_pages(url, limit)\n",
    "    all_infos = []\n",
    "    next_cursor = '*'\n",
    "    for page in tqdm.tqdm(range(1,nb_pages+1)):\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            page_i, next_cursor = get_articles(url,next_cursor,limit)\n",
    "            for article in page_i:\n",
    "                infos = get_basic_infos(article)\n",
    "                all_infos.append(infos)\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            time.sleep(30)\n",
    "            page_i, next_cursor = get_articles(url,next_cursor,limit)\n",
    "            for article in page_i:\n",
    "                infos = get_basic_infos(article)\n",
    "                all_infos.append(infos)\n",
    "            continue\n",
    "          \n",
    "    df = pd.DataFrame(all_infos)\n",
    "    df.to_csv('Data_concept_{}.csv'.format(concept_id))\n",
    "    \n",
    "    works_ids = set()\n",
    "    for refs in df.references.to_list():\n",
    "        refs = re.sub(\"https://openalex.org/\",\"\",refs)\n",
    "        refs = refs.split(\"; \")\n",
    "        works_ids.update(refs)\n",
    "    \n",
    "    path = \"mongodb://\"\n",
    "    import pymongo\n",
    "    client = pymongo.MongoClient(path)\n",
    "    db = client['Stefano']\n",
    "    col = db[concept_id]\n",
    "    \n",
    "    \n",
    "    all_infos = []\n",
    "    works_ids = list(works_ids)[1:]\n",
    "    for i in tqdm.tqdm(range(0,len(works_ids),100)):\n",
    "        to = i+100 if i+100<len(works_ids) else len(works_ids)\n",
    "        work_ids = \"|\".join(works_ids[i:to])\n",
    "        url = \"https://api.openalex.org/works?filter=ids.openalex:{}&per-page=100\".format(work_ids)\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            page_i = get_articles(url)\n",
    "            for article in page_i:\n",
    "                infos = get_basic_infos(article)\n",
    "                col.insert_one(infos)\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            time.sleep(1000)\n",
    "            page_i = get_articles(url)\n",
    "            for article in page_i:\n",
    "                infos = get_basic_infos(article)            \n",
    "                col.insert_one(infos)\n",
    "            continue\n",
    "    \n",
    "    pd.DataFrame(all_infos).to_csv('Data_ref_concept_{}.csv'.format(concept_id))\n",
    "    \n",
    "    df = pd.read_csv('Data_concept_{}.csv'.format(concept_id))\n",
    "    #df_ref = pd.read_csv('Data_ref_concept_{}.csv'.format(concept_id))\n",
    "    df_ref = pd.DataFrame([doc for doc in col.find()])\n",
    "    \n",
    "    df[\"references\"] = df['references'].str.split('; ')\n",
    "    \n",
    "    edgelist_ref = df[[\"id\",\"year\",\"references\"]].explode('references')\n",
    "    edgelist_ref[\"references\"] = edgelist_ref[\"references\"].apply(lambda x:  re.sub(\"https://openalex.org/\",\"\",x) if isinstance(x,str) else None)\n",
    "    \n",
    "    ref_infos = df_ref[[\"id\",\"source\"]]\n",
    "    ref_infos = ref_infos.rename(columns={'id': 'references'})\n",
    "    \n",
    "    merge_infos = edgelist_ref.merge(ref_infos, on = 'references', how = \"left\")\n",
    "    \n",
    "    merge_infos = merge_infos.dropna()\n",
    "    \n",
    "    ref_structured = merge_infos.groupby([\"id\",\"year\"]).apply(lambda x: [ref for ref in x[\"source\"]]).reset_index()\n",
    "    \n",
    "    ref_structured = ref_structured.rename(columns={0: 'refs'})\n",
    "    \n",
    "    ref_structured['id'] = ref_structured['id'].apply(lambda x: int(re.sub('W','',x)))\n",
    "    if not os.path.exists(\"Data/docs/refs/\"):\n",
    "        os.makedirs(\"Data/docs/refs/\")\n",
    "    for y in range(2000,2024):\n",
    "        tmp = ref_structured[ref_structured.year == y]\n",
    "        json.dump(tmp.to_dict('records'),open(\"Data/docs/refs/\"+ \"{}.json\".format(y),'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
