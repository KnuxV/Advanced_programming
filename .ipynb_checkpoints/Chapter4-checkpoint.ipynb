{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Machine learning libraries WORK IN PROGRESS\n",
    "\n",
    "The goal of this chapter is not to run algorithm (You probably have another module for this) but to look into the installation and utilities of Pytorch and Tensorflow.\n",
    "\n",
    "- [Tensorflow and Keras](#TF)\n",
    "- [Pytorch](#Pytorch)\n",
    "- [TODO](#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"TF\"></a>\n",
    "## Tensorflow and Keras\n",
    "\n",
    "TensorFlow is a free and open-source software library written in Pythonand C++. It was created by the Google Brain team in 2015. Really flexible but hard to start coding (Specific syntax). \n",
    "The difficulty to use Tensorflow was one of the reason PyTorch was so popular. Keras is an open-source library written in Python. Is primary author and maintainer is Francois Chollet (https://www.youtube.com/watch?v=PUAdj3w3wO4&t) \n",
    "Keras can run with different machine learning libraries as backend (Tensorflow included). Way easier to use and to understand. Since Tensorflow v2.0 Keras API is direclty available in Tensorflow !\n",
    "\n",
    "```console\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "If you feel like using GPUs: https://www.tensorflow.org/install/gpu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple scalar and array operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple matrix operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion from np -> tf or tf -> np:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so now we will focus on Loading and preprocessing of data using Tensorflow and Keras. Let's start with a csv: california_housing_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also another class of object in tensorflow PrefetchDataset that overcome ram issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "dataset = tf.data.experimental.make_csv_dataset(train_file_path, batch_size=2,label_name=\"survived\",shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('sex', <tf.Tensor: shape=(10000,), dtype=string, numpy=\n",
      "array([b'male', b'male', b'female', ..., b'female', b'male', b'female'],\n",
      "      dtype=object)>), ('age', <tf.Tensor: shape=(10000,), dtype=float32, numpy=array([27.,  3.,  4., ..., 28., 39., 27.], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(10000,), dtype=int32, numpy=array([0, 1, 0, ..., 1, 0, 1])>), ('parch', <tf.Tensor: shape=(10000,), dtype=int32, numpy=array([0, 1, 2, ..., 0, 0, 0])>), ('fare', <tf.Tensor: shape=(10000,), dtype=float32, numpy=\n",
      "array([30.5   , 18.75  , 22.025 , ..., 15.5   ,  7.925 , 13.8583],\n",
      "      dtype=float32)>), ('class', <tf.Tensor: shape=(10000,), dtype=string, numpy=\n",
      "array([b'First', b'Second', b'Third', ..., b'Third', b'Third', b'Second'],\n",
      "      dtype=object)>), ('deck', <tf.Tensor: shape=(10000,), dtype=string, numpy=\n",
      "array([b'unknown', b'unknown', b'unknown', ..., b'unknown', b'unknown',\n",
      "       b'unknown'], dtype=object)>), ('embark_town', <tf.Tensor: shape=(10000,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', ..., b'Queenstown',\n",
      "       b'Southampton', b'Cherbourg'], dtype=object)>), ('alone', <tf.Tensor: shape=(10000,), dtype=string, numpy=array([b'y', b'n', b'n', ..., b'n', b'y', b'n'], dtype=object)>)]), <tf.Tensor: shape=(10000,), dtype=int32, numpy=array([1, 1, 1, ..., 1, 1, 1])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.unbatch().filter(lambda x,y: tf.not_equal(y, 0))\n",
    "dataset = dataset.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrefetchDataset' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-6c772cc150e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "dataset.sample(frac=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Pytorch\"></a>\n",
    "## Pytorch\n",
    "\n",
    "PyTorch is the main competitor of Tensorflow. Developed by Facebook’s AI Research lab (FAIR). Way easier to get into compare to basic Tensorflow. Equivalent to Keras IMO.\n",
    "In the end the library you choose is up to you, some companies will require one or the other (easier if everyone uses the same library).  \n",
    "My recommendation: Try both, assess for which task you use which.  Don’t try to know everything with both.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
