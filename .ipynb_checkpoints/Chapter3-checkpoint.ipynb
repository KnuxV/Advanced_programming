{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: GPU programming.\n",
    "\n",
    "Why do we want to use GPUs ?\n",
    "\n",
    "GPU hardware is designed for data parallelism. Maximum throughput is achieved when you are computing the same operations on many different elements at once.\n",
    "\n",
    "https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html\n",
    "\n",
    "Among the tasks that do significantly benefit from parallel processing is deep learning. Other tasks can't be used in parallel (When you need to have the same object in memory, e.g calculating a series like fibonnaci).\n",
    "\n",
    "One thing that could be nice would be to write the same code as normal (numpy, pandas,..) but just to run computation on a GPU. This would make it easier to parallelize processes. Some companies/university/people are working on this kind of libraries and that's what we are going to use in this section.\n",
    "\n",
    "Structure:\n",
    "- [CuPy](#CuPy)\n",
    "- [Numba](#Numba)\n",
    "- [CuDF](#CuDF)\n",
    "- [CuML](#CuML)\n",
    "- [TODO](#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"CuPy\"></a>\n",
    "## CuPy\n",
    "\n",
    "CuPy is the GPU equivalent to Numpy. CuPy uses the same methods that numpy so cost entry going from Numpy to CuPy is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = cp.arange(6).reshape(2, 3).astype('f')\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.dot(z.T).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ary = cp.arange(10).reshape((2,5))\n",
    "print(repr(ary))\n",
    "print(ary.dtype)\n",
    "print(ary.shape)\n",
    "print(ary.strides)\n",
    "print(ary.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ary_cpu = np.arange(10)\n",
    "ary_gpu = cp.asarray(ary_cpu)\n",
    "print('cpu:', ary_cpu)\n",
    "print('gpu:', ary_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ary_cpu_returned = cp.asnumpy(ary_gpu)\n",
    "print(repr(ary_cpu_returned))\n",
    "print(type(ary_cpu_returned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ary_gpu * 2)\n",
    "print(cp.exp(-0.5 * ary_gpu**2))\n",
    "print(cp.linalg.norm(ary_gpu))\n",
    "print(cp.random.normal(loc=5, scale=2.0, size=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice a slight pause when you run these functions the first time. This is because CuPy has to compile the CUDA functions on the fly, and then cache them to disk for reuse in the future. (kinda the same thing as numba where the first run you convert your function into another \"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cupy as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Chap3/california_housing_train.csv\")\n",
    "intercept = np.ones(len(df))\n",
    "\n",
    "y = np.array(df[\"median_house_value\"])\n",
    "X = np.array(df.drop([\"median_house_value\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gpu = cp.asarray(y)\n",
    "X_gpu = cp.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "beta = np.matmul(np.linalg.inv(np.matmul(X.T,X)),np.matmul(X.T,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "beta = cp.matmul(cp.linalg.inv(cp.matmul(X_gpu.T,X_gpu)),cp.matmul(X_gpu.T,y_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cp.arange(10, dtype=np.float32).reshape(2, 5)\n",
    "y = cp.arange(5, dtype=np.float32)\n",
    "\n",
    "add_reverse = cp.ElementwiseKernel(\n",
    "    'T x, raw T y', \n",
    "    'T z',\n",
    "    '''\n",
    "    z = x + y[_ind.size() - i - 1];\n",
    "    ''',\n",
    "    'add_reverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_reverse(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized CUDA Kernel\n",
    "\n",
    "_fit_calc_distances = cp.ElementwiseKernel(\n",
    "    'S data, raw S centers, int32 n_clusters, int32 dim', 'raw S dist',\n",
    "    '''\n",
    "    for (int j = 0; j < n_clusters; j++){\n",
    "        int cent_ind[] = {j, i % dim};\n",
    "        int dist_ind[] = {i / dim, j};\n",
    "        double diff = centers[cent_ind] - data;\n",
    "        atomicAdd(&dist[dist_ind], diff * diff);\n",
    "    }\n",
    "    ''',\n",
    "    'calc_distances'\n",
    ")\n",
    "\n",
    "_fit_calc_center = cp.ElementwiseKernel(\n",
    "    'S data, T label, int32 dim', 'raw S centers, raw S group',\n",
    "    '''\n",
    "    int cent_ind[] = {label, i % dim};\n",
    "    atomicAdd(&centers[cent_ind], data);\n",
    "    atomicAdd(&group[label], 1);\n",
    "    ''',\n",
    "    'calc_center'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU/GPU-agnostic fit function\n",
    "\n",
    "def fit(X, n_clusters, max_iter, use_custom_kernel):\n",
    "    # make sure that X is a matrix not a tensor\n",
    "    assert X.ndim == 2\n",
    "\n",
    "    #NumPy/CuPy generic function\n",
    "    xp = cp.get_array_module(X)\n",
    "    \n",
    "    # init pred vector\n",
    "    pred = xp.zeros(len(X), dtype=np.int32)\n",
    "\n",
    "    # Choose n_clusters center from X\n",
    "    initial_indexes = np.random.choice(len(X), n_clusters,\n",
    "                                       replace=False).astype(np.int32)\n",
    "    centers = X[initial_indexes]\n",
    "\n",
    "    # init n_obs and n_variables\n",
    "    data_num = X.shape[0]\n",
    "    data_dim = X.shape[1]\n",
    "\n",
    "    # Repeat the process max_iter\n",
    "    for _ in range(max_iter):\n",
    "        # calculate distances between centers and every observation\n",
    "        if not use_custom_kernel or xp == np:\n",
    "            # Multiple way to do this operation.\n",
    "            # You want to calculate the norm for each center : newaxis (None)\n",
    "            distances = xp.linalg.norm(X[:, None, :] - centers[None, :, :],\n",
    "                                       axis=2)\n",
    "        else:\n",
    "            distances = xp.zeros((data_num, n_clusters), dtype=np.float32)\n",
    "            _fit_calc_distances(X, centers, n_clusters, data_dim, distances)\n",
    "\n",
    "        # assign points to the closest center\n",
    "        new_pred = xp.argmin(distances, axis=1).astype(np.int32)\n",
    "\n",
    "        # If nothing changed for the prediction you can stop early the algorithm\n",
    "        if xp.all(new_pred == pred):\n",
    "            break\n",
    "        pred = new_pred\n",
    "\n",
    "        # calculate centers\n",
    "        if not use_custom_kernel or xp == np:\n",
    "            centers = xp.stack([X[pred == i].mean(axis=0)\n",
    "                                for i in range(n_clusters)])\n",
    "        else:\n",
    "            # init centers\n",
    "            centers = xp.zeros((n_clusters, data_dim),\n",
    "                               dtype=np.float32)\n",
    "            # init group\n",
    "            group = xp.zeros(n_clusters, dtype=np.float32)\n",
    "            # label\n",
    "            label = pred[:, None]\n",
    "            _fit_calc_center(X, label, data_dim, centers, group)\n",
    "            group /= data_dim\n",
    "            centers /= group[:, None]\n",
    "\n",
    "    return centers, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y_true = make_blobs(n_samples=100000, centers=10,\n",
    "                       center_box=(-10.0, 10,0),\n",
    "                       cluster_std=1.5, random_state=4)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gpu = cp.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit centers, pred = fit(X, n_clusters=10, max_iter=100, use_custom_kernel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit centers, pred = fit(X_gpu, n_clusters=10, max_iter=100, use_custom_kernel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit centers, pred = fit(X_gpu, n_clusters=10, max_iter=100, use_custom_kernel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Numba\"></a>\n",
    "## Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"CuDF\"></a>\n",
    "## CuDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"CuML\"></a>\n",
    "## CuML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"TODO\"></a>\n",
    "## TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
